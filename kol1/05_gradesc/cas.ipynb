{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ef92dd-7678-4372-a3f7-9aa5800862e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee9ed5f-60a5-409c-b1e7-639d97a9e22c",
   "metadata": {},
   "source": [
    "$$x_{new} = x - \\alpha * \\nabla f(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f33ab769-904d-43d3-9ebe-43566e82cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x0, f, gradient, alpha, num_iters, tol):\n",
    "    result = {}\n",
    "    result['converged'] = False\n",
    "\n",
    "    x = x0\n",
    "    for i in range(num_iters):\n",
    "        x_new = x - alpha * gradient(x)\n",
    "        if abs(f(x_new) - f(x)) < tol:\n",
    "            result['converged'] = True\n",
    "            break\n",
    "        x = x_new\n",
    "\n",
    "    result['iter'] = i\n",
    "    result['x'] = x\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd95c455-93f6-40de-882f-e386a516ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 0.5*(x[0]**2 + 10*x[1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68fe9fc2-a3ac-45af-94fc-020eb303f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x): # vraca f'x(x,y), f'y(x,y)\n",
    "    return np.array([x[0], 10*x[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0bd7f00-2cd4-4b1d-92a9-1c6da2d3f4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'converged': True, 'iter': 996, 'x': array([3.14595031e-02, 1.06561271e-43])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = np.array((700,400))\n",
    "alpha = 0.01\n",
    "num_iters = 10000\n",
    "tol = 1e-5\n",
    "\n",
    "gradient_descent(x0, f, gradient, alpha, num_iters, tol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929fece6-569f-45be-a370-80f9b26e015c",
   "metadata": {},
   "source": [
    "$$inertia = \\beta * inertia - \\alpha * \\nabla f(x)$$\n",
    "$$x_{new} = x + inertia$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d93b91e-4d9a-4425-b827-f83f550a60dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(x0, f, gradient, alpha, num_iters, tol, beta=0.9):\n",
    "    result = {}\n",
    "    result['converged'] = False\n",
    "\n",
    "    x = x0\n",
    "    inertia = 0 ##\n",
    "    for i in range(num_iters):\n",
    "        inertia = beta * inertia - alpha * gradient(x) ##\n",
    "        x_new = x + inertia ##\n",
    "        if abs(f(x_new) - f(x)) < tol:\n",
    "            result['converged'] = True\n",
    "            break\n",
    "        x = x_new\n",
    "\n",
    "    result['iter'] = i\n",
    "    result['x'] = x\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41307631-e53b-4294-ad8e-ca2bea1954df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'converged': True, 'iter': 194, 'x': array([-0.01804139,  0.01335318])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momentum(x0, f, gradient, alpha, num_iters, tol, beta=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908ff93b-22c4-427e-b764-ee2154aab21a",
   "metadata": {},
   "source": [
    "$$inertia = \\beta * inertia - \\alpha * \\nabla f(x + \\beta * inertia)$$\n",
    "$$x_{new} = x + inertia$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af5c1de4-68d1-4b55-a26e-204f7b721713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesterov(x0, f, gradient, alpha, num_iters, tol, beta=0.9):\n",
    "    result = {}\n",
    "    result['converged'] = False\n",
    "\n",
    "    x = x0\n",
    "    inertia = 0\n",
    "    for i in range(num_iters):\n",
    "        inertia = beta * inertia - alpha * gradient(x + beta*inertia) ## isti samo gradient(x + beta*inertia)\n",
    "        x_new = x + inertia \n",
    "        if abs(f(x_new) - f(x)) < tol:\n",
    "            result['converged'] = True\n",
    "            break\n",
    "        x = x_new\n",
    "\n",
    "    result['iter'] = i\n",
    "    result['x'] = x\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4040a1b-ebe4-42cb-bec1-41f04dc2824c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'converged': True,\n",
       " 'iter': 172,\n",
       " 'x': array([ 1.05179270e-03, -2.69569084e-06])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nesterov(x0, f, gradient, alpha, num_iters, tol, beta=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4386b63-2808-4e8b-9df0-e86e7476ba51",
   "metadata": {},
   "source": [
    "$$m = \\beta_1 * m + (1 - \\beta_1) * \\nabla f(x)$$\n",
    "$$v = \\beta_2 * v + (1 - \\beta_2) * \\nabla f(x)^2$$\n",
    "\n",
    "$$m_{hat} = \\frac{m}{1 - \\beta_1^i}$$\n",
    "$$v_{hat} = \\frac{v}{1 - \\beta_2^i}$$\n",
    "\n",
    "\n",
    "$$x_{new} = x - \\alpha * \\frac{m_{hat}}{\\sqrt{v_{hat}} + \\epsilon}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a91e6c3-3511-412e-8a6c-f3f5d2c60997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam(x0, f, gradient, num_iters, tol, beta1, beta2, eps, alpha):\n",
    "    result = {}\n",
    "    result['converged'] = False\n",
    "\n",
    "    x = x0\n",
    "    m = 0 #\n",
    "    v = 0 #\n",
    "    for i in range(1, num_iters+1):\n",
    "        grad = gradient(x)\n",
    "        \n",
    "        m = beta1 * m + (1 - beta1) * grad\n",
    "        v = beta2 * v + (1 - beta2) * grad**2\n",
    "\n",
    "        m_hat = m / (1 - beta1**i)\n",
    "        v_hat = v / (1 - beta2**i)\n",
    "\n",
    "        x_new = x - alpha * m_hat / (np.sqrt(v_hat) + eps)\n",
    "        \n",
    "        if abs(f(x_new) - f(x)) < tol:\n",
    "            result['converged'] = True\n",
    "            break\n",
    "        x = x_new\n",
    "\n",
    "    result['iter'] = i\n",
    "    result['x'] = x\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da91817d-3097-44cd-8e4f-8ff9e4c55d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'converged': True, 'iter': 4117, 'x': array([4.11236404e-02, 1.14925986e-09])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam(x0, f, gradient, num_iters, tol, beta1=0.9, beta2=0.999, eps=1e-6, alpha=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
