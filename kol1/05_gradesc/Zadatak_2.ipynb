{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadatak 2.\n",
    "\n",
    "Jedna od modifikacija osnovne metode gradijentnog spusta je Barzilai-Borvejn metoda u kojoj se korak gradijentnog spusta izraÄunava na osnovu vrednosti gradijenata u dvema taÄkama $x_n$ i $x_{n-1}$ po formuli$$\\gamma_n = \\frac{(x_n-x_{n-1})^T(\\nabla f(x_n)-\\nabla f(x_{n-1}))}{||\\nabla f(x_n)-\\nabla f(x_{n-1})||^2}$$za $n>=2$, a sa namerom da se aproksimira Njutnova metoda i ubrza ceo proces konvergencije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize as opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Implementirati Barzilai-Borvejn metodu koja za zadatu funkciju $f$ dveju promenljivih, njen gradijent $\\nabla f$, poÄetnu taÄku $x_0$ i vrednost koraka $\\gamma_0$ koji se koristi za izraÄunavanje taÄke $x_1$ standardnom gradijentnom iteracijom izraÄunava minimum funkcije $f$. Algoritam zaustaviti ukoliko je broj iteracija veÄ‡i od zadatog ograniÄenja $max\\_iterations$ ili ukoliko je norma gradijenta u tekuÄ‡oj taÄki manja od zadate taÄnosti $\\epsilon$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, gradient, x0, korak, eps, iters):\n",
    "    result = {}\n",
    "    result['Converged'] = False\n",
    "    result['num_iters'] = 0\n",
    "    result['x'] = None\n",
    "    x = x0\n",
    "    for i in range(iters):\n",
    "        d = korak\n",
    "        x_new = x - d\n",
    "        if abs(f(x_new) - f(x)) < eps:\n",
    "            result['Converged'] = True\n",
    "            break\n",
    "        brojilac = np.transpose(x_new - x) * (gradient(x_new) - gradient(x))\n",
    "        imenilac = np.linalg.norm(gradient(x_new) - gradient(x))\n",
    "        korak = brojilac / imenilac\n",
    "        x = x_new\n",
    "    result['x'] = x_new\n",
    "    result['num_iters'] = i\n",
    "    \n",
    "    return result\n",
    "\n",
    "def gradient(x):\n",
    "    return np.array([400*x[0]**3+2*x[0]-400*x[0]*x[1]-2, 200*(x[1]-x[0]**2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Primeniti implementiranu metodu na funkciju $$ğ‘“(a,b)=(1âˆ’a)^2+100(bâˆ’a^2)^2$$\n",
    "\n",
    "Za poÄetnu taÄku uzeti $(2.1,1.3)$, za vrednost koraka $\\gamma_0$ u prvoj iteraciji $0.01$, za maksimalan broj iteracija $100$, a za taÄnost epsilon $10^{-8}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Converged': False, 'num_iters': 99, 'x': array([1.65655195, 1.29136783])},\n",
       " 211.49284021122475)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    return (1-x[0])**2 + 100*(x[1]-x[0]**2)**2\n",
    "\n",
    "x0 = np.array([2.1, 1.3])\n",
    "korak = 0.01\n",
    "iters = 100\n",
    "eps = 10 ** (-8)\n",
    "\n",
    "solution = gradient_descent(f, gradient, x0, korak, eps, iters)\n",
    "solution, f(solution['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Uporediti ovako dobijeno reÅ¡enje sa reÅ¡enjem neke od funkcija biblioteke `scipy.optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 2.4417659543147583e-11\n",
       "        x: [ 1.000e+00  1.000e+00]\n",
       "      nit: 15\n",
       "      jac: [-1.815e-06  4.439e-07]\n",
       " hess_inv: [[ 4.974e-01  9.948e-01]\n",
       "            [ 9.948e-01  1.994e+00]]\n",
       "     nfev: 57\n",
       "     njev: 19"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solucione = opt.minimize(f, x0=x0)\n",
    "solucione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999506, 0.99999011])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solucione['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
